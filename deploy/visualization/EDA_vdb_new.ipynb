{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec2363b-09fe-407f-babd-f21938d3f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "#from langchain_chroma import Chroma\n",
    "import torch\n",
    "import pdb\n",
    "import os\n",
    "from langchain import HuggingFacePipeline\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "model_name  = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs = {'trust_remote_code':True, 'device': torch.device(\"cpu\")})\n",
    "     \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "chroma_dir = '../scripts/PA_200c_named_db'\n",
    "db = Chroma(persist_directory=chroma_dir, embedding_function=embedding_function)\n",
    "\n",
    "# docs=db.similarity_search('what is the best chicken in Mcdonald')\n",
    "# print(docs)\n",
    "     \n",
    "\n",
    "#vdb=db.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "#vdb=db.get(include=[\"embeddings\"])\n",
    "import pandas as pd\n",
    "#vdb=pd.DataFrame(db)\n",
    "#df = pd.DataFrame({\"embeddings\": vdb[\"embeddings\"],})\n",
    "vectors=db.get(include=[\"embeddings\", \"documents\"])\n",
    "# print(vectors)\n",
    "# Convert the embeddings to a numpy array and transpose it\n",
    "#pdb.set_trace()\n",
    "vec_array = np.asarray(vectors['embeddings'])\n",
    "txt_array = np.asarray(vectors['documents'])\n",
    "num_test = 18000\n",
    "#pdb.set_trace()\n",
    "select_randidx = np.random.randint(0,len(vectors['embeddings']),num_test)\n",
    "vec_array = vec_array[select_randidx, :]\n",
    "txt_array  = txt_array[select_randidx]\n",
    "print(\"Original array shape (transposed):\", vec_array.T.shape)\n",
    "\n",
    "\n",
    "datafile = '../data/200chrestReviews_PA.json'\n",
    "df = pd.read_json(datafile, lines=True)\n",
    "meta_df = pd.read_json('../data/meta-Pennsylvania.json', lines=True)\n",
    "\n",
    "#search for query to get gmap id\n",
    "\n",
    "relevant_metadata = ['Noodle', 'Thai'] \n",
    "noodle_list, thai_list = [], []\n",
    "not_found = []\n",
    "for ii, item in enumerate(txt_array):\n",
    "        try:\n",
    "            find_idx = df['text'].str.contains(item[-20:])\n",
    "            get_gmap = df[find_idx]['gmap_id']\n",
    "            get_gmap = get_gmap.iloc[0]\n",
    "            # if len(get_gmap)>1:\n",
    "            #     get_gmap = get_gmap.iloc[df.index[0]]        \n",
    "            #entry = meta_df[meta_df['gmap'] == get_gmap]\n",
    "            categories = meta_df[meta_df['gmap_id'] == get_gmap].reset_index().iloc[0].category\n",
    "        \n",
    "            string_meta = \" \".join(categories)            \n",
    "            if relevant_metadata[0] in string_meta:\n",
    "                noodle_list.append(ii)\n",
    "            if relevant_metadata[1] in string_meta:\n",
    "                thai_list.append(ii)\n",
    "        except:\n",
    "            not_found.append(ii)\n",
    "print(\"Missing \"+ str(not_found)+ \" reviews.\")\n",
    "print(str(len(noodle_list)) + \" noodle reviews found (orange).\")\n",
    "print(str(len(thai_list)) + \" Thai reviews found (yellow).\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the transposed array to a text file\n",
    "# In future add request vector, convenient for plotting\n",
    "text_file_name = 'array_small.text'\n",
    "\n",
    "np.savetxt(text_file_name, vec_array.T, delimiter=',', fmt='%.18e')\n",
    "\n",
    "# Load the array from the text file\n",
    "loaded_array = np.loadtxt(text_file_name, delimiter=',')\n",
    "     \n",
    "\n",
    "## add query vector in\n",
    "from sentence_transformers import SentenceTransformer\n",
    "query=['For the best vegetarian plate, what should I order on the menu at Noodlehead?']\n",
    "\n",
    "#model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "#model = model\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "query_embeddings = model.encode(query)\n",
    "#print(query_embeddings.shape)\n",
    "# Prepare documents for Chroma.from_documents\n",
    "query_vec = query_embeddings\n",
    "query_vec_array=np.asarray(query_vec)\n",
    "\n",
    "#print(query_vec_array.T.shape)\n",
    "#loaded_array = np.random.rand(384, 1)\n",
    "##loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "#print(loaded_array.shape)\n",
    "updated_array = np.hstack([loaded_array, query_vec_array.T])\n",
    "np.savetxt(text_file_name, updated_array, delimiter=',', fmt='%.18e')\n",
    "#loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "#print(\"Updated array shape:\", loaded_array.shape)\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "loaded_array = np.loadtxt(text_file_name, delimiter=',')\n",
    "n_components = 2 #3D\n",
    "# tsne = TSNE(n_components=n_components, random_state=1, perplexity=1)\n",
    "# reduced_vectors = tsne.fit_transform(loaded_array)\n",
    "     \n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Plot the reduced embeddings\n",
    "# plt.scatter(reduced_vectors[:,  0], reduced_vectors[:,  1], c='red', alpha=0.2)\n",
    "\n",
    "# # Add labels and title\n",
    "\n",
    "# plt.show()\n",
    "     \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Directory to save figures\n",
    "save_dir = 'tsne_figures'\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#parameter for tSNE list\n",
    "#perplexity_col = [2,4,8,10]\n",
    "perplexity_col=[50,80,100,200,300]\n",
    "random_state_col=[10,20,40]\n",
    "\n",
    "\n",
    "# Save figures in a loop\n",
    "for i in range(len(perplexity_col)):\n",
    "    for j in range(len(random_state_col)):\n",
    "        tsne = TSNE(n_components=n_components, random_state=random_state_col[j], perplexity=perplexity_col[i])\n",
    "        reduced_vectors = tsne.fit_transform(loaded_array.T)\n",
    "        plt.figure()\n",
    "        plt.scatter(reduced_vectors[:-1, 0], reduced_vectors[:-1,  1], c='purple', alpha=0.2)\n",
    "        for idx in noodle_list:\n",
    "            plt.scatter(reduced_vectors[idx, 0], reduced_vectors[idx,  1], s=64, marker ='*', c='gold')\n",
    "        for idx in thai_list:\n",
    "            plt.scatter(reduced_vectors[idx, 0], reduced_vectors[idx,  1], s=64, marker ='*', c='orange')\n",
    "        plt.scatter(reduced_vectors[-1, 0], reduced_vectors[-1,  1], s=192, marker ='*', c='red')        \n",
    "        filename = os.path.join(save_dir, f'figure_perplex[{perplexity_col[i]}]_randomstate[{random_state_col[j]}].png')  # Create a filename with the loop index\n",
    "        plt.title(\"t-SNE Visualization of Text Embeddings with Question Highlighted\")\n",
    "        plt.xlabel(\"t-SNE  1\")\n",
    "        plt.ylabel(\"t-SNE  2\")        \n",
    "        plt.savefig(filename)  # Save the figure\n",
    "        plt.close()  # Close the figure to free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbb4cb-71d7-42e6-bb46-ef13768dbeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
