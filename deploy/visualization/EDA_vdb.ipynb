{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f945ad0d-70c3-46b4-ad69-def72fd61655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshteyn/anaconda3/envs/huggingface/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original array shape (transposed): (1024, 1800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshteyn/anaconda3/envs/huggingface/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#tsne \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "#from langchain_chroma import Chroma\n",
    "import torch\n",
    "import pdb\n",
    "import os\n",
    "from langchain import HuggingFacePipeline\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "model_name  = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs = {'trust_remote_code':True, 'device': torch.device(\"cpu\")})\n",
    "     \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "chroma_dir = '../scripts/PA_200c_named_db'\n",
    "db = Chroma(persist_directory=chroma_dir, embedding_function=embedding_function)\n",
    "\n",
    "# docs=db.similarity_search('what is the best chicken in Mcdonald')\n",
    "# print(docs)\n",
    "     \n",
    "\n",
    "#vdb=db.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "#vdb=db.get(include=[\"embeddings\"])\n",
    "import pandas as pd\n",
    "#vdb=pd.DataFrame(db)\n",
    "#df = pd.DataFrame({\"embeddings\": vdb[\"embeddings\"],})\n",
    "vectors=db.get(include=[\"embeddings\"])\n",
    "# print(vectors)\n",
    "# Convert the embeddings to a numpy array and transpose it\n",
    "vec_array = np.asarray(vectors['embeddings'])\n",
    "num_test = 18000\n",
    "#pdb.set_trace()\n",
    "select_randidx = np.random.randint(0,len(vectors['embeddings']),num_test)\n",
    "vec_array = vec_array[select_randidx, :]\n",
    "print(\"Original array shape (transposed):\", vec_array.T.shape)\n",
    "\n",
    "# Save the transposed array to a text file\n",
    "# In future add request vector, convenient for plotting\n",
    "text_file_name = 'array_small.text'\n",
    "\n",
    "np.savetxt(text_file_name, vec_array.T, delimiter=',', fmt='%.18e')\n",
    "\n",
    "# Load the array from the text file\n",
    "loaded_array = np.loadtxt(text_file_name, delimiter=',')\n",
    "     \n",
    "\n",
    "## add query vector in\n",
    "from sentence_transformers import SentenceTransformer\n",
    "query=['For the best vegetarian plate, what should I order on the menu at Noodlehead?']\n",
    "\n",
    "#model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "#model = model\n",
    "model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "query_embeddings = model.encode(query)\n",
    "#print(query_embeddings.shape)\n",
    "# Prepare documents for Chroma.from_documents\n",
    "query_vec = query_embeddings\n",
    "query_vec_array=np.asarray(query_vec)\n",
    "\n",
    "#print(query_vec_array.T.shape)\n",
    "#loaded_array = np.random.rand(384, 1)\n",
    "##loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "#print(loaded_array.shape)\n",
    "updated_array = np.hstack([loaded_array, query_vec_array.T])\n",
    "np.savetxt(text_file_name, updated_array, delimiter=',', fmt='%.18e')\n",
    "#loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "#print(\"Updated array shape:\", loaded_array.shape)\n",
    "     \n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "loaded_array = np.loadtxt(text_file_name, delimiter=',')\n",
    "n_components = 2 #3D\n",
    "# tsne = TSNE(n_components=n_components, random_state=1, perplexity=1)\n",
    "# reduced_vectors = tsne.fit_transform(loaded_array)\n",
    "     \n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# # Plot the reduced embeddings\n",
    "# plt.scatter(reduced_vectors[:,  0], reduced_vectors[:,  1], c='red', alpha=0.2)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.title(\"t-SNE Visualization of Text Embeddings with Question Highlighted\")\n",
    "# plt.xlabel(\"t-SNE  1\")\n",
    "# plt.ylabel(\"t-SNE  2\")\n",
    "# plt.show()\n",
    "     \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Directory to save figures\n",
    "save_dir = 'tsne_figures'\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#parameter for tSNE list\n",
    "#perplexity_col = [2,4,8,10]\n",
    "perplexity_col=[50,80,100,200,300]\n",
    "random_state_col=[10,20,40]\n",
    "\n",
    "\n",
    "# Save figures in a loop\n",
    "for i in range(len(perplexity_col)):\n",
    "    for j in range(len(random_state_col)):\n",
    "        tsne = TSNE(n_components=n_components, random_state=random_state_col[j], perplexity=perplexity_col[i])\n",
    "        reduced_vectors = tsne.fit_transform(loaded_array.T)\n",
    "        plt.figure()\n",
    "        plt.scatter(reduced_vectors[:-1, 0], reduced_vectors[:-1,  1], c='purple', alpha=0.2)\n",
    "        plt.scatter(reduced_vectors[-1, 0], reduced_vectors[-1,  1], marker ='*', c='red')\n",
    "        filename = os.path.join(save_dir, f'figure_perplex[{perplexity_col[i]}]_randomstate[{random_state_col[j]}].png')  # Create a filename with the loop index\n",
    "        plt.savefig(filename)  # Save the figure\n",
    "        plt.close()  # Close the figure to free up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a25231b9-71c1-435c-96fe-a8681b9fc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# model_name  = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "# embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs = {'trust_remote_code':True, 'device': torch.device(\"cpu\")})   \n",
    "# query=['what is the best chicken dish in McDonald']\n",
    "# model = SentenceTransformer(model_name, trust_remote_code=True)\n",
    "# query_embeddings = model.encode(query)\n",
    "# query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25daf8bd-4de4-4940-ab0b-7933168e680b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd98775d-e5ba-434d-8e4d-0de6b93c45ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
