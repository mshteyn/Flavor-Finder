{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "#from langchain_chroma import Chroma\n",
    "import torch\n",
    "import pdb\n",
    "import os\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "model_name  = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs = {'trust_remote_code':True, 'device': torch.device(\"cpu\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "chroma_dir = 'PA_200c_named_db'\n",
    "db = Chroma(persist_directory=chroma_dir, embedding_function=embedding_function)\n",
    "\n",
    "# docs=db.similarity_search('what is the best chicken in Mcdonald')\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vdb=db.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "#vdb=db.get(include=[\"embeddings\"])\n",
    "import pandas as pd\n",
    "#vdb=pd.DataFrame(db)\n",
    "#df = pd.DataFrame({\"embeddings\": vdb[\"embeddings\"],})\n",
    "vectors=db.get(include=[\"embeddings\"])\n",
    "# print(vectors)\n",
    "# Convert the embeddings to a numpy array and transpose it\n",
    "vec_array = np.asarray(vectors['embeddings'])\n",
    "print(\"Original array shape (transposed):\", vec_array.T.shape)\n",
    "\n",
    "# Save the transposed array to a text file\n",
    "# In future add request vector, convenient for plotting\n",
    "np.savetxt('array.txt', vec_array.T, delimiter=',', fmt='%.18e')\n",
    "\n",
    "# Load the array from the text file\n",
    "loaded_array = np.loadtxt('array.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "n_components = 2 #3D\n",
    "tsne = TSNE(n_components=n_components, random_state=1, perplexity=1)\n",
    "reduced_vectors = tsne.fit_transform(loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the reduced embeddings\n",
    "plt.scatter(reduced_vectors[:,  0], reduced_vectors[:,  1], c='red', alpha=0.2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(\"t-SNE Visualization of Text Embeddings with Question Highlighted\")\n",
    "plt.xlabel(\"t-SNE  1\")\n",
    "plt.ylabel(\"t-SNE  2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
