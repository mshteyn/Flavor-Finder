{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne \n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "#from langchain_chroma import Chroma\n",
    "import torch\n",
    "import pdb\n",
    "import os\n",
    "from langchain import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, pipeline\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "model_name  = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=model_name, model_kwargs = {'trust_remote_code':True, 'device': torch.device(\"cpu\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "chroma_dir = 'PA_200c_named_db'\n",
    "db = Chroma(persist_directory=chroma_dir, embedding_function=embedding_function)\n",
    "\n",
    "# docs=db.similarity_search('what is the best chicken in Mcdonald')\n",
    "# print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vdb=db.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "#vdb=db.get(include=[\"embeddings\"])\n",
    "import pandas as pd\n",
    "#vdb=pd.DataFrame(db)\n",
    "#df = pd.DataFrame({\"embeddings\": vdb[\"embeddings\"],})\n",
    "vectors=db.get(include=[\"embeddings\"])\n",
    "# print(vectors)\n",
    "# Convert the embeddings to a numpy array and transpose it\n",
    "vec_array = np.asarray(vectors['embeddings'])\n",
    "print(\"Original array shape (transposed):\", vec_array.T.shape)\n",
    "\n",
    "# Save the transposed array to a text file\n",
    "# In future add request vector, convenient for plotting\n",
    "np.savetxt('array.txt', vec_array.T, delimiter=',', fmt='%.18e')\n",
    "\n",
    "# Load the array from the text file\n",
    "loaded_array = np.loadtxt('array.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add query vector in\n",
    "from sentence_transformers import SentenceTransformer\n",
    "query=['what is the best chicken dish in McDonald']\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "query_embeddings = model.encode(query)\n",
    "#print(query_embeddings.shape)\n",
    "# Prepare documents for Chroma.from_documents\n",
    "query_vec = query_embeddings\n",
    "query_vec_array=np.asarray(query_vec)\n",
    "#print(query_vec_array.T.shape)\n",
    "#loaded_array = np.random.rand(384, 1)\n",
    "##loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "#print(loaded_array.shape)\n",
    "updated_array = np.hstack([loaded_array, query_vec_array.T])\n",
    "np.savetxt('array.txt', updated_array, delimiter=',', fmt='%.18e')\n",
    "#loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "#print(\"Updated array shape:\", loaded_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "loaded_array = np.loadtxt('array.txt', delimiter=',')\n",
    "n_components = 2 #3D\n",
    "# tsne = TSNE(n_components=n_components, random_state=1, perplexity=1)\n",
    "# reduced_vectors = tsne.fit_transform(loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Plot the reduced embeddings\n",
    "# plt.scatter(reduced_vectors[:,  0], reduced_vectors[:,  1], c='red', alpha=0.2)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.title(\"t-SNE Visualization of Text Embeddings with Question Highlighted\")\n",
    "# plt.xlabel(\"t-SNE  1\")\n",
    "# plt.ylabel(\"t-SNE  2\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Directory to save figures\n",
    "save_dir = 'tsne_figures'\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "#parameter for tSNE list\n",
    "perplexity_col=[50,80,100,200,300]\n",
    "random_state_col=[10,20,40]\n",
    "\n",
    "\n",
    "# Save figures in a loop\n",
    "for i in range(len(perplexity_col)):\n",
    "    for j in range(len(random_state_col)):\n",
    "        tsne = TSNE(n_components=n_components, random_state=random_state_col[j], perplexity=perplexity_col[i])\n",
    "        reduced_vectors = tsne.fit_transform(loaded_array.T)\n",
    "        plt.figure()\n",
    "        plt.scatter(reduced_vectors[:-1, 0], reduced_vectors[:-1,  1], c='purple', alpha=0.2)\n",
    "        plt.plot(reduced_vectors[-1, 0], reduced_vectors[-1,  1], '*', c='red')\n",
    "        filename = os.path.join(save_dir, f'figure_perplex[{perplexity_col[i]}]_randomstate[{random_state_col[j]}].png')  # Create a filename with the loop index\n",
    "        plt.savefig(filename)  # Save the figure\n",
    "        plt.close()  # Close the figure to free up memory\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
